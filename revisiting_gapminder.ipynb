{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc6d4e14",
   "metadata": {},
   "source": [
    "# Revisiting Gapminder\n",
    "\n",
    "files needed = `conts.csv`\n",
    "\n",
    "On the first day of class, we looked at the gapminder website, in particular, [this figure](https://www.gapminder.org/tools/#$chart-type=bubbles&url=v1).\n",
    "\n",
    "We talked about all the information we could squeeze out the figure. After three months of class, we would say that the figure is **graphically excellent**. \n",
    "\n",
    "On this last day of class, I thought I would walk through constructing this figure and highlight many of the skills we have picked up along the way. \n",
    "\n",
    "Our roadmap:\n",
    "\n",
    "1. Get the data from the World Bank (APIs)\n",
    "2. Extract the data we need (working with dicts, loops, functions; creating DataFrames)\n",
    "3. Create one data set (merging DataFrames; reading from files; dropping observations; calculations in DataFrames)\n",
    "4. Create the figure (interactive figures; visualization best practices; graphical excellence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0f021e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47757761",
   "metadata": {},
   "source": [
    "## 1. Get the data and build a DataFrame: APIs, merging, and cleaning\n",
    "\n",
    "We need data on populations, life expectancy, and GDP. I will get them from the World Bank *World Development Indicators* dataset through the [api](https://datahelpdesk.worldbank.org/knowledgebase/articles/889392-about-the-indicators-api-documentation).\n",
    "\n",
    "After looking up the variable names, I build the urls, request the data, and parse the dicts that are returned. In theory, I should be able to ask for many variables in one api call. I kept getting an error when I tried to, so I am retrieving each series individually. There is always something to debug...\n",
    "\n",
    "This is (unnecessarily) repetitive, so I will write a short function and use a loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528f82b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "urlpop = 'http://api.worldbank.org/v2/country/all/indicator/SP.POP.TOTL?format=json&date=2020&per_page=300'\n",
    "urlgdp = 'http://api.worldbank.org/v2/country/all/indicator/NY.GDP.MKTP.PP.CD?format=json&date=2020&per_page=300'\n",
    "urlexp = 'http://api.worldbank.org/v2/country/all/indicator/SP.DYN.LE00.IN?format=json&date=2020&per_page=300'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea8fb2a-d33e-4efb-902e-bc263206a9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Check how the data are coming in from each URL\n",
    "   in order to set up the function correctly\n",
    "'''\n",
    "response = requests.get(urlpop)\n",
    "#response.json()[1]\n",
    "#response.json()[1][0]\n",
    "#response.json()[1][0]['country']\n",
    "#response.json()[1][0]['country']['value']\n",
    "#response.json()[1][0]['countryiso3code']\n",
    "#response.json()[1][0]['date']\n",
    "#response.json()[1][0]['value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74257fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_df(j, col):\n",
    "    '''\n",
    "    Given the dict retrieved from the WB api, extract the country name, \n",
    "    iso, date, and the variable. Return a DataFrame.\n",
    "    '''\n",
    "    names, codes, dates, var = [], [], [], []\n",
    "    for c in j[1]:\n",
    "        names.append(c['country']['value'])\n",
    "        codes.append(c['countryiso3code'])\n",
    "        dates.append(c['date'])\n",
    "        var.append(c['value'])\n",
    "        \n",
    "    return pd.DataFrame({'country name':names, 'iso':codes, 'date':dates, col:var})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da80583b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through the three urls. Each call to json_df returns a DataFrame. \n",
    "# I am collecting the DataFrames into a dict. 'v' will be the name of the column.\n",
    "dfs = {}\n",
    "for url, v in zip([urlpop, urlgdp, urlexp], ['pop', 'gdp', 'exp']):\n",
    "    response = requests.get(url)\n",
    "    dfs[v] = json_df(response.json(), v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc775ee-aef5-4430-86bb-3a7400e62458",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs['gdp'].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4459332",
   "metadata": {},
   "source": [
    "## 3. Create one DataFrame\n",
    "Now I have three DataFrames in the dict `dfs`. Merge them together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7250cb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge data\n",
    "data = pd.merge(left=dfs['pop'], right=dfs['gdp'], on=['country name', 'iso', 'date'])\n",
    "data = pd.merge(left=data, right=dfs['exp'], on=['country name', 'iso', 'date'])\n",
    "data.set_index('iso', inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f682529",
   "metadata": {},
   "source": [
    "### Data cleaning\n",
    "\n",
    "The data include a bunch of country aggregates. I bet there is a way to drop these when I get the data from the World Bank. Maybe I can figure it out for version 2.0 of this notebook. I'm also dropping any countries with missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c543154d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop countries, missing\n",
    "aggs = ['AFE', 'AFW', 'ARB', 'CSS', 'CEB', 'EAR', 'EAS', 'EAP', 'TEA', 'EMU', 'ECS', 'ECA', 'EUU', 'FCS', 'TEC',\n",
    "       'HPC', 'IBD', 'IBT', 'IDB', 'IDX', 'IDA', 'LTE', 'LCN', 'LAC', 'TLA', 'LDC', 'LMY', 'MEA', 'MNA', 'TMN', 'MIC',\n",
    "       'NAC', 'OED', 'OSS', 'PSS', 'PST', 'PRE', 'SST', 'SAS', 'TSA', 'SSF', 'SSA', 'TSS', 'WLD', '']\n",
    "\n",
    "data.drop(aggs, inplace=True)\n",
    "data.dropna(subset=['pop', 'gdp', 'exp'], inplace=True)\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077ed619",
   "metadata": {},
   "source": [
    "The WB data do not include a 'continent' variable. The file 'conts.csv' has the information I need in it. One more merge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fddf56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge data\n",
    "data = pd.merge(left=data, right=pd.read_csv('conts.csv'), left_index=True, right_on='iso')\n",
    "data = data.rename(columns={'cont':'Regions'})\n",
    "data.set_index('iso', inplace=True)\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901c0259",
   "metadata": {},
   "source": [
    "Looking ahead, I know that I will want a log base-2 x-axis to match the gapminder figure. I'm creating the gdp per capita value and then taking the log. I take a look at the US as a sanity check. GDP per capita of 63K looks about right. Notice that $2^{15.9477}=63206.$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596824f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate variables\n",
    "data['gdpcap'] = data['gdp']/data['pop']\n",
    "data['gdpcaplog2'] = np.log2(data['gdpcap'])\n",
    "data.loc['USA']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f289646",
   "metadata": {},
   "source": [
    "## 4. The figure: interactive figures, graphical excellence\n",
    "\n",
    "Let's run the code and check out the figure. Then we can go back and look at the code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3895e86f-1306-40e4-9c9a-765b9f053f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['gdpcaplog2'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c1f116",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The x data are in log base two. They numbers between 9 and 16. Most people \n",
    "would not find these labels very intuitive, so we are going to replace the labels \n",
    "with ones that are easy to read. We'll use numpy (np) and a list comprehension.\n",
    "'''\n",
    "\n",
    "xv = [500, 1000, 2000, 4000, 8000, 16000, 32000, 64000, 128000]\n",
    "xticklabs = ['500', '1000', '2000', '4000', '8000', '16K', '32K', '64K', '128K']\n",
    "xtickvals = [np.log2(x) for x in xv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fa2895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plots\n",
    "fig = px.scatter(data, x='gdpcaplog2', y='exp'\n",
    "#                 , size='pop'\n",
    "#                 , color='Regions'\n",
    "#                 , hover_name='country name'\n",
    "#                 , hover_data={'gdpcaplog2':False, 'exp':False, 'pop':False, 'Regions':False}\n",
    "#                 , size_max=60\n",
    "#                 , color_discrete_map={'Asia':'#ff798e', 'Europe':'#ffec33', 'Africa':'#33dded', 'Americas':'#99ef33'}\n",
    "                )\n",
    "\n",
    "fig.update_layout(plot_bgcolor='white',\n",
    "                  xaxis={'title':'GDP per capita (Price and inflation-adjusted, in PPP$2017)', \n",
    "#                         'tickmode':'array', 'tickvals':xtickvals, 'ticktext':xticklabs,\n",
    "                         'gridcolor':'lightgray'},\n",
    "#                 xaxis_range=[min(xtickvals)-1,max(xtickvals)+.1],\n",
    "                  yaxis={'title':'Life expectancy','gridcolor':'lightgray'},\n",
    "                  yaxis_range=[0,100],\n",
    "#                  hoverlabel={'bgcolor':'white'}\n",
    "                  )\n",
    "\n",
    "fig.update_traces(marker={'line':{'width':0.75, 'color':'black'}})\n",
    "\n",
    "# Style the axes\n",
    "fig.update_xaxes(showline=True, linewidth=1, linecolor='black'\n",
    "#                 , showspikes=True, spikemode='across', spikethickness=1.5, spikecolor='lightgray'\n",
    "                )  \n",
    "\n",
    "fig.update_yaxes(showline=True, linewidth=1, linecolor='black'\n",
    "#                 , showspikes=True, spikemode='across', spikethickness=1.5, spikecolor='lightgray'\n",
    "                )\n",
    "\n",
    "# The annotation for the big \"2020\"\n",
    "#fig.add_annotation(x=13, y=50, text='2020', showarrow=False,\n",
    "#                  font={'size':100, 'color':'lightgray'}, opacity=0.75)\n",
    "\n",
    "import plotly.io as pio\n",
    "\n",
    "pio.write_html(fig, \n",
    "               file='gap_minder.html', \n",
    "               full_html = True, \n",
    "               auto_open=False, \n",
    "               config={'displayModeBar': False, 'showTips': False, 'responsive': True}\n",
    "              )\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb66f1cd",
   "metadata": {},
   "source": [
    "### The x axis\n",
    "\n",
    "Check out the x axis. Each grid line is a doubling of income. The x data are transformed into their log base-2 values. For example, Afghanistan's GDP per capita is 2078. The log2 of 2078 is 11.02:  \n",
    "$$2^{11.02} = 2078$$\n",
    "\n",
    "So the real units on the x axis run from about 9.5 to 16. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdf2b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f3927c",
   "metadata": {},
   "source": [
    "I do not want the log values on the axis. So I will set the values manually. \n",
    "```python\n",
    "xv = [500, 1000, 2000, 4000, 8000, 16000, 32000, 64000, 128000]\n",
    "xtickvals = [np.log2(x) for x in xv]\n",
    "```\n",
    "\n",
    "The `xv` list holds the (base 10) values I want as tick marks. They could be any values I wanted as ticks. The `xtickvals` are these values translated to base 2. These are the values of the tick marks. \n",
    "\n",
    "The labels can be any arbitrary text. I could have just used `xv` as the labels, but I decided to go with the 'K' notation from the website. \n",
    "```python\n",
    "xticklabs = ['500', '1000', '2000', '4000', '8000', '16K', '32K', '64K', '128K']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f204dd",
   "metadata": {},
   "source": [
    "### Spikes \n",
    "\n",
    "When I hover on a dot, I get two lines that point out the values on the axis. These are 'spikes' and we style them with `.update_xaxes()`.\n",
    "\n",
    "```python\n",
    "fig.update_xaxes(showline=True, linewidth=1, linecolor='black', \n",
    "                 showspikes=True, spikemode='across', spikethickness=1.5, spikecolor='lightgray')  \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031c1a06",
   "metadata": {},
   "source": [
    "### Colors\n",
    "\n",
    "We have always used named colors in our work: 'black', 'red', 'skyblue'. matplotlib, plotly, etc. allow for very fine control of color. There several ways to specify a specific color. The two most popular are probably by its [hex number](https://en.wikipedia.org/wiki/Web_colors) or its [rgb values](https://en.wikipedia.org/wiki/RGB_color_model). \n",
    "\n",
    "I used a [color picker](https://imagecolorpicker.com/en) and a screen shot from gapminder to get the colors right. \n",
    "\n",
    "```python\n",
    "color_discrete_map={'Asia':'#ff798e', 'Europe':'#ffec33', 'Africa':'#33dded', 'Americas':'#99ef33'}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6935f2",
   "metadata": {},
   "source": [
    "### Bubble charts\n",
    "\n",
    "If you look through our matplotlib/seaborn notebooks, we discussed bubble charts. A bubble chart scales the size of the data point marker by some third variable. In our case, it is the population of the country. \n",
    "\n",
    "```python\n",
    "fig = px.scatter(data, x='gdpcaplog2', y='exp', size='pop', size_max=60)\n",
    "```\n",
    "\n",
    "`size_max` sets the size of the largest bubble in the figure and the rest are scaled down from there. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464000a3",
   "metadata": {},
   "source": [
    "Not bad for a semester's work!"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
